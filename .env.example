# SADIE Environment Variables
# ============================================
# DEV-ONLY: Example .env file for local development. 
# Do NOT include a real .env in release artifacts.
# The preflight script will block builds that include dangerous flags.
#
# Copy this to `.env` during development and set values as needed.
# ============================================

# ============================================
# Core Configuration
# ============================================

# Ollama server URL (default: http://localhost:11434)
OLLAMA_URL=http://localhost:11434

# n8n webhook URL (optional - SADIE uses direct Ollama by default)
N8N_URL=http://localhost:5678

# ============================================
# External API Keys (Optional)
# ============================================
# These can also be configured in the Settings UI

# OpenAI API Key (for GPT models)
# OPENAI_API_KEY=sk-...

# Anthropic API Key (for Claude models)
# ANTHROPIC_API_KEY=sk-ant-...

# Google AI API Key (for Gemini models)
# GOOGLE_API_KEY=...

# ============================================
# Logging Configuration
# ============================================

# Log level: debug, info, warn, error (default: info in production, debug in dev)
SADIE_LOG_LEVEL=debug

# ============================================
# Development / Testing (DO NOT USE IN PRODUCTION)
# ============================================

# Enable E2E test mode (internal use only)
# SADIE_E2E=true

# Direct Ollama mode bypass (for testing without n8n)
# SADIE_DIRECT_OLLAMA=true

# ============================================
# Advanced Configuration
# ============================================

# Custom n8n streaming endpoint
# N8N_STREAM_URL=http://localhost:5678/webhook/sadie/chat/stream

# Proxy URL (if using a proxy server)
# SADIE_PROXY_URL=
